{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "nteract": {
      "version": "0.15.0"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RVJMXQnwgmf"
      },
      "source": [
        "# LX 496/796  Introduction -- Poetry in NLTK\n",
        "\n",
        "***Due Friday at 11:59 PM in Gradescope***\n",
        "\n",
        "In this first homework, you will become familiar with programming in Python on Jupyter Notebooks (in Google Colaboratory), and some problem solving while getting familiar with NLTK (the Natural Language Toolkit).\n",
        "\n",
        "We will be submitting homeworks (in the form of Jupyter Notebooks) directly to Gradescope.  Later ones will involve an autograder, but for this one:\n",
        "- Choose \"Download\" and \"ipynb\" from the File menu, to save a local copy.\n",
        "- Upload the `.ipynb` file to Gradescope.  I will just look at it there and potentially add comments. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyi8X12gwgmq"
      },
      "source": [
        "---\n",
        "\n",
        "# Haiku assignment\n",
        "\n",
        "\n",
        "\n",
        "People can argue about this, but let's just say that something will qualify as haiku if it is in three lines, with specific syllable counts: 5-7-5.  Thus:\n",
        "\n",
        "> Haikus are easy\n",
        ">\n",
        "> But sometimes they don't make sense\n",
        ">\n",
        "> Refrigerator\n",
        "\n",
        "(This haiku might be attributable to Rolf Nelson.)\n",
        "\n",
        "So, suppose that we want to use a corpus to create such things.  We need to be able to determine whether we have met the syllable constraints.  Let's do that with the CMU pronunciation corpus."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3vK_Ei8wgmr"
      },
      "source": [
        "import nltk"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldlwDBkGwgmr"
      },
      "source": [
        "The line above is how we always want to start, since that makes NLTK available to us.\n",
        "\n",
        "The CMU pronunciation corpus has pronunciations for a large set of words, and it is easy to use it with NLTK.  The Colab notebook won't have it available by default, so we want to download it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUmwZybEwgmr"
      },
      "source": [
        "nltk.download('cmudict')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2LI35LH_wgmr"
      },
      "source": [
        "The download above should get the corpus so we can use it. Once it is downloaded, we make Python aware of it by using `import`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OzohsWYwgms"
      },
      "source": [
        "from nltk.corpus import cmudict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QE89XUQVwgms"
      },
      "source": [
        "One of the ways we can look at the CMU pronunciation corpus is in the form of a (Python data type) \"dictionary\", so we'll ask the corpus for that form.  So if we want to look up the pronunciation of a word like \"trimmed\", we ask the dictionary what value it has for key `trimmed`.\n",
        "\n",
        "> If you don't remember or were not already familiar with the dictionary data type, you can [read up on it at pythontutorial.net](https://www.pythontutorial.net/python-basics/python-dictionary/) or [in the official documentation](https://docs.python.org/3/tutorial/datastructures.html#dictionaries) or [in the NLTK book](https://www.nltk.org/book/ch05.html#sec-dictionaries).  It's a key-value mapping.  It is like a list but indexed by key instead of position."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cmudict.dict()['trimmed']"
      ],
      "metadata": {
        "id": "rmEQQc5H0ZxQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "We can also give it a name (`pro`), so that we don't need to type out `cmudict.dict()` all the time.  This is arguably simpler to understand.  The equivalent way to look up \"trimmed\" is then as below."
      ],
      "metadata": {
        "id": "uFiAaZDs0I3K"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKlcOMinwgms"
      },
      "source": [
        "pro = cmudict.dict()\n",
        "pro['trimmed']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYwaF78Hwgms"
      },
      "source": [
        "The output for \"trimmed\" above looked a little bit strange because it started with two square brackets.  But this is meaningful and intentional.  The information we wanted (\"how do you pronounce 'trimmed'?\") is represented as a list (an ordered sequence of \"phones\"), starting with a \"T\", followed by an \"R\", followed by an \"IH\" vowel with primary stress, etc.  We know it's a list because it has entries seperated by commas and surrounded by square brackets.  This accounts for the innermost square brackets above, but the outermost brackets also are defining a list. That is, we have a list containing one thing: a list of five phones."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDJokf4Xwgms"
      },
      "source": [
        "---\n",
        "\n",
        "## TASK 1. The pronunciation representation\n",
        "\n",
        "The goal here is to work out how we can, given a word, find the number of syllables.  To do this:\n",
        "- retrieve the pronunciation for \"fire\"\n",
        "- retrieve the pronunciation for \"madelyn\"\n",
        "\n",
        "And look at what you got.\n",
        "\n",
        "In the code cell, retrieve the pronunciations.  Then in the markdown cell, write down how what you learned about how many syllables \"fire\" and \"madelyn\" have and how you can get from the results you retrieved to that answer.  Specifically: we're going to make a list of 1-syllable words, of 2-syllable words, of 3-syllable words, etc. Which lists do 'fire' and 'madelyn' go in?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lqp89ceEwgms"
      },
      "source": [
        "# Answer 1a: put code here to get and print the pronunciations for 'fire' and 'madelyn'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_F4sdtPPwgmt"
      },
      "source": [
        "**Answer 1b:** (replace this with your answer: which lists do 'fire' and 'madelyn' go into, and how can you determine that from the retrieved pronunciations?)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3j8-x81wgmt"
      },
      "source": [
        "---\n",
        "\n",
        "## TASK 2 Define `count_syllables`\n",
        "\n",
        "In this task we will construct a function called `count_syllables()` that, given a word (a string), will look up the pronunciation, count the syllables in the first pronunciation variant and return the number of syllables.  We will build it up in stages.\n",
        "\n",
        "The shape of the function would be like that below, except of course in its final form we want it not to just return 2 all the time but instead count the syllables in `word` and return that number.\n",
        "\n",
        "```\n",
        "def count_syllables(word):\n",
        "  num_syllables = 2 # TODO: actually count the syllables\n",
        "  return num_syllables\n",
        "```\n",
        "So how do we count the syllables?\n",
        "\n",
        "The first thing we are going to need to do is look up the pronunciation of the word that is passed in.  We know from above that when we look up the pronunciations of `word` using `pro[word]`, we get a list.  If we want the first (and often only) pronunciation from that list, we need to focus on the first element.  How do we get the first element of a list? Right. So, the list of phones we are going to check (the first pronunciation) is `pro[word][0]`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# if word were 'sixths' then the first pronunciation is\n",
        "phones = pro['sixths'][0]\n",
        "print(phones)"
      ],
      "metadata": {
        "id": "y7IV5kVUToVc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each element in this list of phones will look like  `IH1` or `S` or `TH`.  To figure out how many syllables are in that we need to count how many have a stress mark (that is, ends in a `0`, `1`, or `2`).  How can we get the last letter of an arbitrary string?  Remember that you can use a negative index in a slice in order to count backwards from the end.  A string can be treated as a list of characters, so we can count backwards from the end of that as well. The NLTK book made use of a special function `isdigit()` that we can use here to distinguish digits from non-digits, and that is good enough to separate the stressed phones from the non-stressed phones."
      ],
      "metadata": {
        "id": "Ss5MZHpUU_dE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The last character of the second phone of sixths is:\")\n",
        "last_of_second = phones[1][-1]\n",
        "print(last_of_second)\n",
        "print(\"Is it a digit?\")\n",
        "print(last_of_second.isdigit())"
      ],
      "metadata": {
        "id": "MN7AZaK-VD3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So what we want is to know how many phones of the word end in digits.  Put another way, how long is the list of phones in the word that end in digits?  That's the goal.  That's the function you will write.\n",
        "\n",
        "To set this up, I'll give you some similar code.  Suppose we instead wanted to find out how many phones start with \"S\". The following list comprehension will accomplish that, by making a list containing just those phones that start with \"S\" and then computing the length of the list."
      ],
      "metadata": {
        "id": "_Aamw0M6WiBC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sphones = [x for x in phones if x[0] == 'S']\n",
        "print(sphones)\n",
        "print(len(sphones))"
      ],
      "metadata": {
        "id": "_yCoRy4LWgmE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So we can just adapt that list above so that instead of looking for phones beginning with \"S\" it looks for phones that end in a digit.  Then the length of that list will be the number of syllables. So then we want to set `num_syllables` to be the length of that list.\n",
        "\n",
        "Now we can finally get to your part. Define the `count_syllables` function like shown a little ways above, except instead of just returning 2, having it take the first pronunciation of the word, count the number of phones that end in a digit, and return that number.  Note: the assumption for now is going to be that the word is actually in the pronunciation dictionary, so there will always be at least one pronunciation.\n"
      ],
      "metadata": {
        "id": "gn_gspMBX4RR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Answer 2. Define count_syllables (replace the stresses = line with code)\n"
      ],
      "metadata": {
        "id": "uKCWinuKX5mo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you have succeeded, you should get 2 for `count_syllables('fire')`, 5 for `count_syllables('participated')`, 3 for `count_syllables('madelyn')`.\n",
        "\n"
      ],
      "metadata": {
        "id": "iiH88Wu7UGA1"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7aXcq6O4wgmu"
      },
      "source": [
        "print('fire: yep' if count_syllables('fire') == 2 else 'fire: nope') # is it 2?\n",
        "print('madelyn: yep' if count_syllables('madelyn') == 3 else 'madelyn: nope') # is it 3?\n",
        "print('participated: yep' if count_syllables('participated') == 5 else 'participated: nope') # is it 5?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you're very concise, you can get the code for `count_syllables` all on one line without using a variable like `num_syllables`, in a form abstractly started below. Once you have it working above, you will probably see what I mean.  This is at this point just artistic. The main thing is just to get `count_syllables()` to return the number of syllables, however you do it.\n",
        "\n",
        "```python\n",
        "    return len([x for x in #... etc. \n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "BTgVZQ0NYm5_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58A_ogywwgmu"
      },
      "source": [
        "---\n",
        "\n",
        "Back to the haiku generation. We want to construct lines of 5 and 7 syllables.  An easy way to do this is to just pick three words (two that are 5 syllables long, one that is 7 syllables long) and use those.  This would lead to inspired haikus like:\n",
        "\n",
        "```python\n",
        "situational\n",
        "anesthesiology\n",
        "agricultural\n",
        "```\n",
        "\n",
        "But we already know that eventually we are going to want to use smaller words too, such that we might have several words on one line that, together, are five or seven syllables.\n",
        "\n",
        "Minimally, we're going to need to know what the 2 syllable words are, the 3 syllable words, the 4 syllable words, and so forth.  So that when we are trying to complete a line, we know what words are available.\n",
        "\n",
        "We could build each list by saying: go through the list of pronunciations, and pull out the 1 syllable words.  Then, go through the list of pronunciations and pull out the 2 syllable words.  Then the 3 syllable words.  And so forth.\n",
        "\n",
        "But you can see that this means we need to go through all of the pronunciations *seven times* and for each word each time through, compute how many syllables it is so we can see if it matches the number of syllables we're looking for.  If our pronunciation dictionary is very large, this could be a serious amount of wasted work.  We can make this *much* more efficient by setting up seven bins, then going through the words, computing the number of syllables for each word only once, and putting it in the correct bin once we know what the number of syllables is.  (You can see why we would do this if you imagined doing it by hand, or imagine that there are a million words in the pronunciation dictionary and it takes 1 minute per word to compute the number of syllables.  In reality things are much faster and smaller, but that's no real excuse for being grossly inefficient.)\n",
        "\n",
        "So, let's do that, even right now from the outset.\n",
        "\n",
        "Our next task is going to be to go through all of the pronunciations, and build up seven lists (one per number of syllables up to seven) containing words with that number of syllables."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U79y0Qkkwgmu"
      },
      "source": [
        "---\n",
        "\n",
        "## TASK 3 Define `sort_words` \n",
        "\n",
        "Define a function `sort_words(pro)` that will take the pronunciation dictionary and return a list, seven members long, such that the *n*th member of the list (counting from 1) is a list of words that have a pronunciation that is *n* syllables long."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Q_MlRmvwgmv"
      },
      "source": [
        "This is complex enough that it no longer lends itself to a simple list comprehension.  We want to make a proper function with loops.\n",
        "\n",
        "To begin, we'll start with some empty bins, so the skeleton of the function would look like this:\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sort_words(pro): # version 1\n",
        "  sorted_words = [[], [], [], [], [], [], []]\n",
        "  # go through the words in pro\n",
        "  # drop them into the right bins\n",
        "  return sorted_words"
      ],
      "metadata": {
        "id": "vPu9pb6mXIc7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Then, we go through the words in `pro`.  That loop is pretty simple, so adding it to the skeleton above, we now have:\n"
      ],
      "metadata": {
        "id": "Vr8KBDCSXKCC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sort_words(pro): # version 2\n",
        "  sorted_words = [[], [], [], [], [], [], []]\n",
        "  for w in pro:\n",
        "    # drop them into the right bins\n",
        "    pass\n",
        "  return sorted_words"
      ],
      "metadata": {
        "id": "dcZMGNADXZ0s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The pronunciations of a word are retrieved with `pro[w]`, and recall this is a list of pronunciations, possibly with more than one.  So we need to go through the pronunciations in `pro[w]`.  Adding that into the skeleton gives us:\n"
      ],
      "metadata": {
        "id": "Mw8guYN0XLmG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sort_words(pro): # version 3\n",
        "  sorted_words = [[], [], [], [], [], [], []]\n",
        "  for w in pro:\n",
        "    for p in pro[w]:\n",
        "      # drop w into bin for syllables in p\n",
        "      pass\n",
        "  return sorted_words"
      ],
      "metadata": {
        "id": "07tPvaRlXMmO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Now we are at the point where we need to count syllables (that is, stress marks) in the pronunciation `p`.  You can't use the\n",
        "`count_syllables()` function from before because that was looking at only the first pronunciation of a word.  But you can use the same technique.\n",
        "\n",
        "Specifically, you can make a list comprehension that will collect together all of the phones in `p` that end in a digit, and then take the `len()` of that list to see how many stress marks (syllables) there were.  If there were 2, then you add the word (`w`) to the bin for 2-syllable words (which is `sorted_words[1]`, keeping in mind that the first bin has index 0).  The way you add `w` to `sorted_words[1]` is: `sorted_words[1].append(w)`.\n",
        "\n",
        "In general, you add the word `w` to the bin whose index is the number of syllables in `p` minus 1.  So long as the number of syllables is at least 1 and fewer than 8. \n",
        "\n",
        "Because you should be left with *something* to figure out and submit, this is the part of the function that you can fill in yourself.  It will go in place of the comment in the skeleton developed above, and it will involve counting the number of syllables, checking to see if it is fewer than 8, and adding the word to the list if so."
      ],
      "metadata": {
        "id": "_A-LLPJhXOb3"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P110zB5swgmv"
      },
      "source": [
        "# Answer 3: define sort_words(pro) returning a list of words organized by syllables"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDLagrZwwgmv"
      },
      "source": [
        "To test this function, run the code below.  I got 3924 for the number of 5-syllable words, and 122 for the number of 7-syllable words, that should match what you got."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MR-Fxkzswgmv"
      },
      "source": [
        "sorted_words = sort_words(pro)\n",
        "print('5-syllable words: yep' if len(sorted_words[4]) == 3924 else '5-syllable words: nope') # is it 3924?\n",
        "print('7-syllable words: yep' if len(sorted_words[6]) == 122 else '7-syllable words: nope') # is it 122?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6WLe-GBwgmv"
      },
      "source": [
        "---\n",
        "\n",
        "We are now going to write a function that prints terrible haikus, by just choosing 5 and 7 syllables words at random.  In order to get access to Python's random number functions, we need to import them now."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qeF7GQRvwgmv"
      },
      "source": [
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6JKxhGRwgmw"
      },
      "source": [
        "Picking a random element from a list is pretty straightforward."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOrBIXIvwgmw"
      },
      "source": [
        "AList = ['A','B','C','D','E','F','G','H']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Sn86kqNwgmw"
      },
      "source": [
        "ALetter = random.choice(AList)\n",
        "print(ALetter)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7B2AN0nJwgmw"
      },
      "source": [
        "For seconds of amusement, you can re-run the cell above a few times (repeatedly press Ctrl-Return) and observe the degree to which it has made a random choice each time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlJ5_P23wgmw"
      },
      "source": [
        "---\n",
        "\n",
        "## TASK 4 Define `bad_haiku`\n",
        "\n",
        "Here, we will write a function `bad_haiku()` that prints terrible haikus.  Specifically, it will pick two 5 syllable words at random, and one 7 syllable word at random, and print the 7 syllable word between the two 5 syllable words."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_AR1Unitwgmw"
      },
      "source": [
        "To get you started: We want to define a function, so this would start like `def bad_haiku():` and it does not need to return anything.  Instead it will just `print()` to the screen.\n",
        "\n",
        "Once you have done `import random` then you can make a choice (for the middle line) from a list of 5-syllablue results, like this:\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "middle_line = random.choice(sorted_words[6])\n",
        "print(middle_line)"
      ],
      "metadata": {
        "id": "d294YM5faOEG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "That should pick a random seven-syllable word and print it.\n",
        "\n",
        "So `bad_haiku()`is just going to find a random 5-syllable line, a random 7-syllable line, and another random 5-syllable line, and print them.\n",
        ">\n",
        "*Note*: You can combine things more concisely, and, rather than finding words first and then printing them, you can print a word as you find it (and thus not need to store the word in a variable), like `print(random.choice(sorted_words[4]))`"
      ],
      "metadata": {
        "id": "Y8s463PEaQyi"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5degUKfuwgmx"
      },
      "source": [
        "# Answer 4a: define a bad_haiku() function to print 5-7-5 lines\n",
        "# then execute it a couple of times to print the haikus\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer 4b. Provide a couple of the bad haikus you got here."
      ],
      "metadata": {
        "id": "ECKqTAhVC1-Q"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhYYrHXAwgmy"
      },
      "source": [
        "---\n",
        "\n",
        "## Task 5 Define `slightly_less_bad_haiku`\n",
        "\n",
        "The haikus above are pretty terrible haikus.  It would be nice if at least it would be able to combine some shorter words to make the 5 and 7 syllable lines.  Maybe stylistically, we'd like to keep the last line at a single word, but the others really should be made of shorter words if we're going to convince anyone that we have produced something deep and meaningful.\n",
        "\n",
        "In this task we will define a function `slightly_less_bad_haiku()` that prints randomly chosen words in a 2-3 / 4-1-2 / 5 pattern.\n",
        "\n",
        "We'll be getting things like this:\n",
        "\n",
        "```python\n",
        "backstage schueneman\n",
        "electrocute cross flagship\n",
        "accommodating\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXrMEZYlwgmy"
      },
      "source": [
        "In Python, if you just use `print(\"something\")`, it will print `something` to the screen, and then move the cursor down to the left (in other words, it prints a return character).  If you want to print something with a customized ending (like a space, or nothing), you can specify this with `end=`. So, observe what happens below.  This will of course be of use when we are printing several words to a line."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54ho0Pgywgmy"
      },
      "source": [
        "print(\"Line one\")\n",
        "print(\"Line two\")\n",
        "print(\"One\", end=' ')\n",
        "print(\"Two\", end=' Pizza time!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lfv_mWIfwgmy"
      },
      "source": [
        "So, now just define `slightly_less_bad_haiku` so that it prints a three-line haiku with two words, then three, then one, in a 2-3/4-1-2/5 patter.  Be sure that the first three words are printed together on a line. It is going to be very much like the definition of `bad_haiku`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arjHXA0Awgmy"
      },
      "source": [
        "# Answer 5a: define slightly_less_bad_haiku() to print 2-3/4-1-2/5 haikus."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer 5b. Put a couple of the slightly less bad haikus you got here."
      ],
      "metadata": {
        "id": "gYD6q7eOEB3e"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7GV1b1Xwgmy"
      },
      "source": [
        "---\n",
        "\n",
        "## TASK 6 Define `sums_to`\n",
        "\n",
        "There are a couple of different ways to create a 5 or 7 syllable line.  Above we used words of 2, 3, and 5 syllables in a fixed pattern.  But to be more flexible, we could use all kinds of combinations that can add to 5.  It could be five 1-syllable words, it could be 1-2-1-1, or 1-3-1.  There are many options.  And many more options for a 7-syllable line.\n",
        "\n",
        "The goal of the next part is to pick a random word to start a line, and figure out how many syllables that leaves us with, then pick a random word to continue, and repeat.\n",
        "\n",
        "Doing it by hand, it might look like this:\n",
        "\n",
        " - Pick a number from 1 to 7.  Suppose we picked 4.\n",
        " - Pick a four syllable word, it turns out to be \"electrocute\".\n",
        " - We are aiming for 7, so we have 3 syllables left to fill.\n",
        "     - Pick a number from 1 to 3. Suppose we picked 1.\n",
        "     - Pick a one syllable word, it turns out to be \"cross\".\n",
        "     - We are aiming for 3, so we have 2 syllables left to fill.\n",
        "         - Pick a number from 1 to 2. Suppose we picked 2.\n",
        "         - Pick a two syllable word, it turns out to be \"flagship\".\n",
        "         - We have filled our 2 syllables.\n",
        "     - Which means, with \"cross\", we have filled our 3 syllables.\n",
        " - Which means, with \"electrocute\", we have filled our 7 syllables.\n",
        " - Our line is \"electrocute cross flagship\".\n",
        "\n",
        "What we want to do is write a function to do this for us.\n",
        "\n",
        "To illustrate how this could work, we will take a diversion to write a function that will just come up with numbers that add up to some target. Then afterwards, we will revise it to work with words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oicHoY59wgmz"
      },
      "source": [
        "def sums_to(total):\n",
        "    new_number = random.randrange(total) + 1\n",
        "    remaining = total - new_number\n",
        "    if remaining == 0:\n",
        "        number_list = [new_number]\n",
        "    else:\n",
        "        number_list = [new_number] + sums_to(remaining)\n",
        "    return number_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oyVSFYxwgmz"
      },
      "source": [
        "# When I use `print(sums_to(7))` three different times, I get \n",
        "#  three different answers, like this:\n",
        "\n",
        "print(sums_to(7))\n",
        "print(sums_to(7))\n",
        "print(sums_to(7))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nO7Oa0RGwgmz"
      },
      "source": [
        "The way `sums_to` works is a little bit weird (that is to say, it's recursive).  I'll walk through it here, and I'll repeat the line I'm talking about as I talk about it.  I'll intersperse a couple of questions as we go.\n",
        "\n",
        "```python\n",
        "new_number = random.randrange(total) + 1\n",
        "```\n",
        "\n",
        "First it finds a random (integer) number greater than or equal to 0, and less than `total`.  This is accomplished using `random.randrange(total)`.  (`random.randrange()` is like `range()` in that the number you provide is one higher than the function can reach.  So `range(15)` gives a list of numbers from 0 to 14, but not 15; and `random.randrange(15)` could return anything from 0 to 14, but not 15.)  Since we don't want to include 0, we add one, meaning that `new_number` winds up able to be any number from 1 to 15."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6Z-iLjSwgmz"
      },
      "source": [
        "---\n",
        "\n",
        "### TASK 6a Why not zero?\n",
        "\n",
        "Why don't we want to include 0?  Answer that below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIJFq7rrwgmz"
      },
      "source": [
        "Answer 6a: (put here why we do not want to allow `new_number` to be zero)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6TVmQblwgmz"
      },
      "source": [
        "---\n",
        "\n",
        "Ok, continuing on:\n",
        "\n",
        "```python\n",
        "    remaining = total - new_number\n",
        "```\n",
        "\n",
        "This determines how many we have left after our new number before the numbers add up to the `total`.  So, for a `total` of 15, if `new_number` turned out to be 10, then `remaining` would be 5.  That is, we have to find more numbers that add up to 5.\n",
        "\n",
        "```python\n",
        "    if remaining == 0:\n",
        "        number_list = [new_number]\n",
        "```\n",
        "\n",
        "It's possible that we are finished already.  If the number we picked is already as big as the total we are aiming for, then the list we will return (`number_list`) can be just the simple list containing that one number.\n",
        "\n",
        "```python\n",
        "    else:\n",
        "        number_list = [new_number] + sums_to(remaining)\n",
        "```\n",
        "\n",
        "If, on the other hand, we still have more numbers to find, then the list we want to return is one that contains this number (`new_number`) and then some more numbers that add up to `remaining`.  We (will) already have a way to find a list of numbers that add up to `remaining`, it is this very function we are defining now.  So we can return the list containing `new_number` and the numbers that `sums_to(remaining)` finds.\n",
        "\n",
        "```python\n",
        "    return number_list\n",
        "```\n",
        "\n",
        "Then we return the `number_list` we created in one of the two last code fragments.\n",
        "\n",
        "If your brain hurts now, or you suspect witchcraft, welcome to the world of recursive programming.  Even though it seems kind of intuitive if you were doing this yourself as a human, the weird thing about `sums_to` is that in that penultimate line we actually *use the function we are defining as part of its definition.*  Why does this not simply cause the universe to implode?\n",
        "\n",
        "If you actually trace it through and think about what it is doing, it may make a little bit more sense.  Also, it works like the haiku-by-hand example above, really.  But let me try to represent this in a table (below).  The explanation is below the table, but the idea is that as part of computing `sums_to(15)` we need to compute `sums_to(5)` first.  And as part of computing `sums_to(5)` we need to compute `sums_to(2)` first."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9SR2XnCwgmz"
      },
      "source": [
        "<table>\n",
        "    <tr>\n",
        "        <td>sums_to(15)\n",
        "        </td>\n",
        "        <td>\n",
        "        </td>\n",
        "        <td>\n",
        "        </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>picked 10 (5 remain)\n",
        "        </td>\n",
        "        <td>\n",
        "        </td>\n",
        "        <td>\n",
        "        </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>(find a list that adds to 5)</td>\n",
        "        <td>&rarr; sums_to(5)</td>\n",
        "        <td>\n",
        "        </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>\n",
        "        </td>\n",
        "        <td>picked 3 (2 remain)\n",
        "        </td>\n",
        "        <td>\n",
        "        </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>\n",
        "        </td>\n",
        "        <td>(find a list that adds to 2)</td>\n",
        "        <td>&rarr; sums_to(2)</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>\n",
        "        </td>\n",
        "        <td>\n",
        "        </td>\n",
        "        <td>picked 2 (none remain)\n",
        "        </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>\n",
        "        </td>\n",
        "        <td>([2] is such a list])</td>\n",
        "        <td>&larr; return [2]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>([3, 2] is such a list])</td>\n",
        "        <td>&larr; return [3] + [2]</td>\n",
        "        <td>\n",
        "        </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>&larr; return [10] + [3, 2]<br />a.k.a. [10, 3, 2]</td>\n",
        "        <td>\n",
        "        </td>\n",
        "        <td>\n",
        "        </td>\n",
        "    </tr>\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnXnKn1bwgm0"
      },
      "source": [
        "In words: We were computing `sums_to(15)`.  We picked a random number, it was **10**.  That by itself does not add to 15.  In addition to the **10**, we need a list of numbers that will add up to the remaining 5.  `sums_to(5)` can find a list with that property.   While computing `sums_to(5)`, we pick a random number, and it was **3**.  That does not add to 5, we also need a list of numbers that will add up to the remaining 2.  So, we call `sums_to(2)` to get such a list.  It randomly picks **2**, which does add up to 2 (that was the goal), so it returns `[2]`, which is a list that adds up to 2.  We can now finish evaluating `sums_to(5)`, which adds the `[3]` it found to the `[2]` it got back, and returns `[3, 2]` (which is a list that adds up to 5).  And then we can finish evaluating `sums_to(15)`, it adds the `[10]` it found to the `[3, 2]` it got back, and returns `[10, 3, 2]` (which is a list that adds to 15).\n",
        "\n",
        "I went through all that because we can use this (pretty directly) to construct a list of words whose syllables add up to five, or seven, or whatever we want.  Really, the only difference between `sums_to()` and the function that we want for our haiku-maker is that instead of making lists of numbers, we want to make lists of words.\n",
        "\n",
        "The next step is to write a function `construct_line(total)` that takes a number of syllables (`total`) and returns a list of words whose syllable lengths add up to the number of syllables passed in.  We're going to base this on `sums_to(total)`.  Before we actually get to the part where you define that function, there are several points to make.\n",
        "\n",
        "The first point is: There's an easy way to do this, since we have `sums_to(total)` already.  We could just do the following:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ike0gjnwgm0"
      },
      "source": [
        "def easy_construct_line(total):\n",
        "    return [random.choice(sorted_words[n-1]) for n in sums_to(total)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ktf7vlpIwgm0"
      },
      "source": [
        "print(easy_construct_line(5))\n",
        "print(easy_construct_line(7))\n",
        "print(easy_construct_line(5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlUfEhk_wgm0"
      },
      "source": [
        "But there is a reason that I don't want to do it quite this way.  The problem is that we are going to (in a little bit) make the choice of the second word be based on the choice of the first word.  We want to make these haikus flow a little bit more naturally.  The idea is that there might be 4 words that often follow the first one, and we want to use one of them as the second word in our haiku.  It shouldn't matter how long they are if they fit, just that they are one of the common continuations.  So instead of picking a length and then looking for a word of that length, it will be better to pick a word out of the set of common continuations and then afterwards look at its length.\n",
        "\n",
        "The line in `sums_to(total)` that is relevant is this one:\n",
        "\n",
        "```python\n",
        "    new_number = random.randrange(total) + 1\n",
        "```\n",
        "\n",
        "What this does is picks a number that is among the possible continuations (since the possible continuations are numbers up to the total amount we are looking for).  To translate this into picking words in a haiku line, we want to pick a word that is among the possible continuations.  That would be any word that has fewer syllables than the total number we are looking for.\n",
        "\n",
        "So let's make a list of the words that are sufficiently short to fit on the rest of the line.  If there are three syllables left, that would include all of the 3-syllable, 2-syllable, and 1-syllable words.  And then we'll just pick one, see how long it was, and then proceed.\n",
        "\n",
        "We already have `sorted_words`, which is a list of words sorted by lengths.  So, `sorted_words[0]` are the 1-syllable words, `sorted_words[1]` are the 2-syllable words, etc.  If we have 2 syllables left on our line, then we want all of the words in *either* `sorted_words[0]` *or* `sorted_words[1]` to be candidates for continuation.  So, let's tranform this `sorted_words` list into one organized by possible continuations.  We can call it `next_words`, and it will be like this: `next_words[0]` is a list of 1-syllable words, the only things you can use if you have only 1 syllable left on the line.  `next_words[1]` is a list of either 1- or 2-syllable words, which are options if you have 2 syllables left on the line.  All of the words in `next_words[0]` are also in `next_words[1]`.\n",
        "\n",
        "To construct `next_words` elegantly is a little bit complicated, so rather than try to get you to write it yourself, I'll provide the function I ended up with and ask you about it.  Below it is defined, and then tested."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vztosUDAwgm0"
      },
      "source": [
        "def construct_next_words(sorted_words):\n",
        "    next_words = []\n",
        "    cumulative_words = []\n",
        "    for i in range(7):\n",
        "        word_pairs = [(w, i + 1) for w in sorted_words[i]]\n",
        "        cumulative_words.extend(word_pairs)\n",
        "        next_words.append(list(set(cumulative_words)))\n",
        "    return next_words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mI5p0a0owgm0"
      },
      "source": [
        "next_words = construct_next_words(sorted_words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUok8yj6wgm1"
      },
      "source": [
        "print(len(sorted_words[0])) # the number of 1-syllable words\n",
        "print(len(next_words[0])) # the number of words we can use if 1 syllable remains\n",
        "print(len(sorted_words[1])) # the number of 2-syllable words\n",
        "print(len(next_words[1])) # the number of words we can use if 2 syllables remain\n",
        "print(next_words[0][-1]) # the last of the 1-syllable-left possibilities\n",
        "print(next_words[1][-1]) # the last of the 2-syllables-left possibilities"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFy2Sp-3wgm1"
      },
      "source": [
        "---\n",
        "\n",
        "## TASK 7 What list is `word_pairs` set to, inside the loop?\n",
        "\n",
        "To show that you understand what `construct_next_words(sorted_words)` is doing, consider the step where `i` is 2.  Describe the list that `word_pairs` gets set to in that iteration.\n",
        "\n",
        "> This is probably the hardest question so far here.  I expect you will need to stare at this for a little while, so don't be worried if you have to.  I wrote this last year, and now that I've gone back to look at it again, *I* needed to stare at it for a while.  But keep in mind what we want it to give us.  We have the words sorted by how long they are, and what we get back are the words sorted by whether they would fit in the remaining syllables.  So we expect the 1-syllable words to be in all of those lists, since no matter how many syllables we have left (assuming we aren't already done) a 1-syllable word would fit in the remaining space.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MvSVQUIwgm1"
      },
      "source": [
        "Answer 10: (markdown)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## TASK 8 1-syllable continuations?\n",
        "\n",
        "An interesting oddity is that, a couple of cells above, we see that the number of 1-syllable words seems to be bigger than the number of possible 1-syllable continuations.  What migght have led to that?\n",
        "\n",
        "> When the continuations are built, the `set()` function is used.  That must be eliminating some.  Why might that be? "
      ],
      "metadata": {
        "id": "fH0W-gUlIm8J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer 8. Why are n-syllable continuations smaller than the sorted n-syllable words?"
      ],
      "metadata": {
        "id": "t2wTrXz6JsSl"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckc94ekowgm1"
      },
      "source": [
        "---\n",
        "\n",
        "## TASK 9 Define `construct_line`\n",
        "\n",
        "Write a function `construct_line(total)` that takes a number of syllables (`total`) as an argument and returns a list of words whose syllables add up to the number of syllables that was passed in.  Use the lists in `next_words` for the source of the random words."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1rzEJskwgm1"
      },
      "source": [
        ">As indicated earlier, we are going to model `construct_line(total)` directly on `sums_to(total)`.  The two functions will be almost identical.  The line we want to focus on for changing is the line that, in `sums_to(total)`, reads:\n",
        ">\n",
        ">```python\n",
        ">    new_number = random.randrange(total) + 1\n",
        ">```\n",
        ">\n",
        ">Instead of a random number, we want a random word.  It should be a word that has at most `total` syllables, and now that we have defined `next_words` we can use that.  Specifically, we can find a word that has `total` or fewer syllables by just doing this:\n",
        ">\n",
        ">```python\n",
        ">    new_word_pair = random.choice(next_words[total-1])\n",
        ">```\n",
        ">\n",
        ">The word we picked will be `new_word_pair[0]` and the number of syllables it has will be `new_word_pair[1]`.  So after having picked the word, we will want to determine how many syllables are left by subtracting `new_word_pair[1]` from `total`.\n",
        ">\n",
        ">With that much guidance, define `construct_line(total)` based on `sums_to(total)` but so that it returns a list of words instead of a list of numbers.  You should rename the variables `number_list` and `new_number` to be more sensible for words, like `word_list` and `new_word_pair`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpF16-Uawgm1"
      },
      "source": [
        "# Answer 9: define construct_line(total) to return a list of words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fW4D0Qsvwgm1"
      },
      "source": [
        "---\n",
        "\n",
        "If this worked, you should get a couple of (still pretty random) haikus by running the next cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwTflEO4wgm1"
      },
      "source": [
        "print(' '.join(construct_line(5)))\n",
        "print(' '.join(construct_line(7)))\n",
        "print(' '.join(construct_line(5)))\n",
        "print()\n",
        "print(' '.join(construct_line(5)))\n",
        "print(' '.join(construct_line(7)))\n",
        "print(' '.join(construct_line(5)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBwPO5qbwgm2"
      },
      "source": [
        "These haikus are still pretty terrible.  It's just random words jumbled together.  So, let's take one last step to trying to make these more palatable.  *Spoiler*: they're still going to be terrible.\n",
        "\n",
        "The plan is to use bigrams and conditional frequency distributions to try to chain the words together better, so that as much as possible, the choice of what word comes next is constrained by what has been seen to come next in the corpus.\n",
        "\n",
        "We'll look at the \"romance\" category of the Brown corpus (since this seems most likely to provide poetry). The idea is that we will look at a \"romance\" word, find out how many syllables it has by looking up its pronunciation, and then proceed to the next word based on words that have been seen to follow it in the \"romance\" corpus.  Notice that this means we need to be able to find the \"romance\" word in the pronunciation corpus (because we need to know how many syllables it has).  So, this is only going to work for words that are in both corpora.  Another point about this: The Brown corpus contains some words that are capitalized, but all of the words in the CMU pronunciation corpus are lowercase.  So, as a first step, we will extract the \"romance\" category, and then make it all lowercase."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2eMGIPawgm2"
      },
      "source": [
        "nltk.download('brown')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpOgfxwawgm2"
      },
      "source": [
        "from nltk.corpus import brown\n",
        "corp = brown.words(categories='romance')\n",
        "lc_corp = [w.lower() for w in corp]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vv8iohQxwgm2"
      },
      "source": [
        "Just to see what we've done here, let's look at the first 10 words of each corpus."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8adLnpowgm2"
      },
      "source": [
        "print(corp[:10])\n",
        "print(lc_corp[:10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7YkK1LHwgm2"
      },
      "source": [
        "Now that we have the corpus in lowercase, we can form the bigrams (the pairs of word and next word) using `bigrams(lc_corp)` but then eliminate all of those that contain words we cannot look up in the pronunciation corpus.  So, below, we form `pairs_in_cmu` by going through each bigram `(x,y)` and adding it to the list only when both `x` and `y` are in our pronunciation corpus."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fi-K_25Lwgm2"
      },
      "source": [
        "from nltk.util import bigrams\n",
        "pairs_in_cmu = [(x,y) for (x,y) in bigrams(lc_corp) if x in pro and y in pro]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbxjlCN2wgm2"
      },
      "source": [
        "Now. Here is what we want to do. We want to know for any given word (that we can pronounce), what words have been seen to follow that word.  So, this means that we look in our list of bigrams (`pairs_in_cmu`) for everything that has, as its first element, the given word.  The set of observed second elements of those pairs are the words that have been observed following our given word.\n",
        "\n",
        "It might be clearer seeing it in code. The following list comprehension will give us a list of words (that we can pronounce) that have been seen to follow \"angry\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVfAko8iwgm3"
      },
      "source": [
        "[y for (x,y) in pairs_in_cmu if x == 'angry']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8AhOIidwgm3"
      },
      "source": [
        "So if we wanted to find a word that follows \"angry\", we could pick one of those words at random. Notice that \"at\" is in there twice, because it was twice observed to follow \"angry\". That's ok, this also gives us the possible benefit that, because it was seen twice as often as any other word, it has twice the chance of any other word of being randomly picked now.\n",
        "\n",
        "It is possible to construct these lists for all of the first elements of the words in `pairs_in_cmu` and then use those lists to decide what to pick next when you are moving through the line of poetry.  However, NLTK already provides a way to do something like this, given its usefulness to language processing tasks.  It is called a \"Conditional Frequency Distribution.\"  It seems a little complicated, but really, it is just a generalization of what we did just above, collecting all the words that follow \"angry\".  You make a conditional frequency distribution with a list of bigrams, so:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbDhAL7Owgm3"
      },
      "source": [
        "cfd = nltk.ConditionalFreqDist(pairs_in_cmu)\n",
        "cfd['angry']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtZDEY_qwgm3"
      },
      "source": [
        "You can see that we got just the same result, though this is now a \"frequency distribution\" and so it is counting the number of occurrences.  Since \"at\" occurred twice, it is paired with 2.  In fact, you can tell from the way it is printed, in a kind of key-value format, that you could further ask `cfd['angry']` how often \"at\" occurred, as compared to \"had\":"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8WinYQZwgm3"
      },
      "source": [
        "cfd['angry']['at']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rs_z4F5Qwgm3"
      },
      "source": [
        "cfd['angry']['had']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yiPp8Wdtwgm3"
      },
      "source": [
        "Ok, now, the idea is to construct lines where each subsequent word has been seen following the preceding word, hoping that this will increase coherence of our language.  (Notice that this is not being smart at all about how language works, it's just offloading the work to the previously-collected corpus we are relying on.  We assume the corpus put words in a sensible order, so we'll try to mimic that and hope our haiku winds up putting words in a similarly sensible order.)\n",
        "\n",
        "As a way to get started, let's see how we would do this partially by hand.\n",
        "\n",
        "Let's suppose that we start with \"unhappy\" and we are aiming for a line of 5 syllables long.  Since \"unhappy\" is 3 syllables long, we have 2 left.  Let's see what words have been known to follow \"unhappy\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDVHkyzwwgm3"
      },
      "source": [
        "cfd['unhappy']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZjQBLp6wgm4"
      },
      "source": [
        "Let's see which of those are among the options we have in our list of words that we can use if we have 2 syllables left."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtPhoB9Wwgm4"
      },
      "source": [
        "options = [(w,s) for (w,s) in next_words[1] if w in cfd['unhappy']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3qPp2y3wgm4"
      },
      "source": [
        "print(options)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNVaHYCvwgm4"
      },
      "source": [
        "So, we could finish up a 5 syllable line by making it \"unhappy success\".  That sounds moderately poetic."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-1e7rmowgm4"
      },
      "source": [
        "Now, we will try to formalize this into a new version of the `construct_line()` function.  I will call it `construct_better_line()` and like before, we need to tell it how many syllables the line should have.  So, it should start *something* like this:\n",
        "\n",
        "```python\n",
        "def construct_better_line(total):\n",
        "```\n",
        "\n",
        "But that's not quite good enough. The `construct_better_line()` function is used each time we need to find a next word, but now the choice of the next word depends on what the previous word was.  So the function needs access to the previous word, not just the target length.  That means that we need to add the previous word as one of the things that the function takes as an argument.  So, really, it should be something like this:\n",
        "\n",
        "```python\n",
        "def construct_better_line(total, previous_word):\n",
        "```\n",
        "\n",
        "But if we're just starting a line at the beginning, there is no previous word.  Python has a special value for things that don't exist, called `None`.  We can set up this function with a \"default\" for the `previous_word` such that, if no previous word is provided, it is assumed to be `None`. Like so:\n",
        "\n",
        "```python\n",
        "def construct_better_line(total, previous_word = None):\n",
        "```\n",
        "\n",
        "This means there are two situations to consider, one where we have a previous word (we are in the middle of a line), and one where we don't (we are at the beginning of a line).  If there is no previous word, the choice of the next word is relatively unconstrained, we can just pick a random word (that has fewer than `total` syllables).  If there is a previous word, then we need to consult the conditional frequency distribution we built from the bigrams.  You can test for whether `previous_word` is `None` or not by treating `previous_word` as if it were a True/False value.  `None` will evaluate as `False`, anything else will evaluate as `True`.\n",
        "\n",
        "```python\n",
        "def construct_better_line(total, previous_word = None):\n",
        "    if previous_word:\n",
        "        # select the next word based on the previous one\n",
        "    else:\n",
        "        # select the first word however we like\n",
        "```\n",
        "\n",
        "Let's start with what happens if we are at the beginning of a line.  I demonstrated this above by starting with \"unhappy\".  Can you just pick any random word?  Well, let's see."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RieRCnBwwgm4"
      },
      "source": [
        "---\n",
        "\n",
        "## TASK 10 Followers of Linda\n",
        "\n",
        "How many different words can follow \"linda\"?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKziX9mxwgm4"
      },
      "source": [
        "# Answer 12: How many different words can follow \"linda\"?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mo3xdmb6wgm4"
      },
      "source": [
        "**Answer 12**: (markdown)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMS47FPvwgm5"
      },
      "source": [
        "---\n",
        "\n",
        "## TASK 11 Following socially\n",
        "\n",
        "One of the words that can follow \"linda\" is \"socially\".  So we know that \"socially\" is in both corpora.  How many different words can follow \"socially\"?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eD1Ycf0lwgm5"
      },
      "source": [
        "# Answer 13: How many different words can follow \"socially\"?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYYiXb1Awgm5"
      },
      "source": [
        "**Answer 13**: (markdown)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtflABRmwgm5"
      },
      "source": [
        "---\n",
        "\n",
        "It is not guaranteed that there will be continuations available from any word you pick.  It might be that there simply are no examples in the corpus of words following the word you picked, or it might be that all of the examples there are have too many syllables to fit on what's left of your line.  We will probably need to deal with this contingency, but at least when we are starting a line, we want to pick a word that has somewhere to go.\n",
        "\n",
        "So, let's make a list of good starting words.  The plan is to find the 100 words with the highest number of possible following words, and when we start a new line, we will pick one of those.  This doesn't really address the issue directly, but it's a fairly easy way to give the haiku generator a fighting chance.\n",
        "\n",
        "We need to know for each word how many continuations it has.  Recall that above we discovered that \"unhappy\" has 4 continuations.  We can get this number directly by taking the length of the frequency distribution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qF-7d4Yjwgm5"
      },
      "source": [
        "cfd['unhappy']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2dYfxdfwgm5"
      },
      "source": [
        "len(cfd['unhappy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLds8Uxowgm5"
      },
      "source": [
        "So let's compute this for every word in `cfd`.  We can make that list as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mpx8dWcwgm5"
      },
      "source": [
        "num_next = [(len(cfd[x]), x) for x in cfd]\n",
        "num_next[:3]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjhk94gGwgm6"
      },
      "source": [
        "If we sort this, it will sort it by the first element in the pair, which is what we want.  This is sorting it in order of number of continuations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNfCOispwgm6"
      },
      "source": [
        "sorted_next = sorted(num_next)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuc2i08uwgm6"
      },
      "source": [
        "print(sorted_next[:3]) # least continuable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCp4gd5Dwgm6"
      },
      "source": [
        "print(sorted_next[-3:]) # most continuable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRK31N58wgm6"
      },
      "source": [
        "The words with the most continuations are at the end (it sorts from low to high), and so the 100 \"most continuable\" words would be `sorted_next[-100:]`.  Let's assume that we are not going to want to choose among those most continuable words based on differences in their continuability, and transform the list so it contains just the words (not the continuation).  In other words, we want to do a list comprehension that extracts just the word."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_liLbeqawgm7"
      },
      "source": [
        "good_starts = [w for (n, w) in sorted_next[-100:]]\n",
        "print(good_starts[:5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QB5s_Wqmwgm8"
      },
      "source": [
        "Getting back to what happens at the beginning of a line in `construct_better_line`, we want to pick one of those \"good starts\" as the next word if there is no previous word.  It is possible that some of those words have too many syllables, though.  It's not really likely, but we should still take that into account.  So, we need to filter the list so that it just has words that have fewer than `total` syllables, and then make a random choice from among those.\n",
        "\n",
        "The simplest way to do this is to filter the options list by whether each is in `good_starts`.  Recall that built the `options` list for \"unhappy\" before like this:\n",
        "\n",
        "```python\n",
        "options = [(w,s) for (w,s) in next_words[1] if w in cfd['unhappy']]\n",
        "```\n",
        "\n",
        "We will still want that form for when we are continuing from a word, but the task at hand is to continue when there was no previous word.  So we filter on whether the word is a good start."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrON4IX9wgm8"
      },
      "source": [
        "total = 7 # we aim to construct a line of length 7\n",
        "options = [(w,s) for (w,s) in next_words[total-1] if w in good_starts]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqavsVhIwgm9"
      },
      "source": [
        "If we embed this into the function we are building up, we wind up with this:\n",
        "\n",
        "```python\n",
        "def construct_better_line(total, previous_word = None):\n",
        "    if previous_word:\n",
        "        # select the next word based on the previous one\n",
        "    else:\n",
        "        # select the first word however we like\n",
        "        options = [(w,s) for (w,s) in next_words[total-1] if w in good_starts]\n",
        "```\n",
        "\n",
        "Thinking ahead, we can expect that the block that executes if we have a previous word will also provide a list of options for the next word, so let's add something outside the conditional that will pick one of the options as the next word.\n",
        "\n",
        "```python\n",
        "def construct_better_line(total, previous_word = None):\n",
        "    if previous_word:\n",
        "        # select the next word based on the previous one\n",
        "    else:\n",
        "        # select the first word however we like\n",
        "        options = [(w,s) for (w,s) in next_words[total-1] if w in good_starts]\n",
        "    word = random.choice(options)\n",
        "```\n",
        "\n",
        "And now we need to determine whether we are done, or whether we need to get more words.  The choice of `word` is a pair, where the first element is the word and the second element is its length.  So it is relatively easy to see if we are done.  If we reached `total`, just return what we have.  If we have a ways to go, we return what we have so far and what `construct_better_line` gives us for the remaining syllables.\n",
        "\n",
        "```python\n",
        "def construct_better_line(total, previous_word = None):\n",
        "    if previous_word:\n",
        "        # select the next word based on the previous one\n",
        "    else:\n",
        "        # select the first word however we like\n",
        "        options = [(w,s) for (w,s) in next_words[total-1] if w in good_starts]\n",
        "    word = random.choice(options)\n",
        "    remaining = total - word[1]\n",
        "    line = [word[0]]\n",
        "    if remaining > 0:\n",
        "        line += construct_better_line(remaining, word[0])\n",
        "    return line\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PV7GrXxQwgm9"
      },
      "source": [
        "That has covered the case where we had no previous word.  We can now turn our attention to what happens when `construct_better_line()` is called with a previous word.  In that case, we need to figure out what the possible continuations are from that word, filter them down to just those that do not have too many syllables, and pick one of them.\n",
        "\n",
        "We were just reminded above of how we find the continuation options from a single word (as we did sort of by hand for \"unhappy\").  Now is the time to deploy that.  We know how many syllables remain (so we know which available continuations to draw from), and we have the word (so we know where to look in `cfd`).  And the structure of the function we are building allows us to just set `options` in the conditional, and use the rest of the function as it is already written.  So:\n",
        "\n",
        "```python\n",
        "def construct_better_line(total, previous_word = None):\n",
        "    if previous_word:\n",
        "        # select the next word based on the previous one\n",
        "        options = [(w,s) for (w,s) in next_words[total-1] if w in cfd[previous_word]]\n",
        "```\n",
        "\n",
        "And that is almost it.  Assuming you followed the discussion above, you should be able to assemble it into the full definition of `construct_better_line()`.  There is just one case left that we should consider:\n",
        "\n",
        "It is possible that no following word is found at all.  Recall how many words followed \"socially\".  If we wind up adding \"socially\" to a line with syllables left to go, we can't continue.  So we need to decide what to do.  The simplest thing is just to say that if there is nowhere to go, pick a new start from among the good starts.\n",
        "\n",
        "This leads me/us to a slight reorganization of the structure in order to allow fractionally more elegance.  We will set a flag `continuing` to be, by default, false.  This indicates whether we are continuing from a prior word.  If there is a previous word and we find a continuation, then we set this flag to true.  Then, if we are not continuing (meaning either that there was no previous word, or there was one but it didn't provide any options), we pick a new word from among our good starts.\n",
        "\n",
        ">Note: there is a failure case that is not being considered here, which is if there are no good starts that are short enough for the number of syllables that are left.  Because \"a\" is for sure in our good starts, this won't arise.  However, if the good starts list is further filtered in a way that could leave it with no 1-syllable words, this could come up.\n",
        "\n",
        "```python\n",
        "def construct_better_line(total, previous_word = None):\n",
        "    continuing = False\n",
        "    if previous_word:\n",
        "        # select the next word based on the previous one\n",
        "        options = [(w,s) for (w,s) in next_words[total-1] if w in cfd[previous_word]]\n",
        "        if len(options) > 0:\n",
        "            continuing = True            \n",
        "    if not continuing:\n",
        "        # select the first word however we like\n",
        "        options = [(w,s) for (w,s) in next_words[total-1] if w in good_starts]\n",
        "```\n",
        "\n",
        "Ok, now you have all the pieces to assemble `construct_better_line()`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olYQFQnRwgm9"
      },
      "source": [
        "---\n",
        "\n",
        "## TASK 12 Define `construct_better_line`\n",
        "\n",
        "Define `construct_better_line()` as described above, such that it (where possible) will pick from words it has seen following the current word."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nP8POGx6wgm9"
      },
      "source": [
        "# Answer 14: Define construct_better_line(total, previous_word = None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0F5mFl0rwgm9"
      },
      "source": [
        "---\n",
        "\n",
        "If it worked, the following should provide some haikus that, frankly, are still terrible.  But maybe have a little bit of flow."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zswgwsTwgm9"
      },
      "source": [
        "for i in range(3):\n",
        "    print(' '.join(construct_better_line(5)))\n",
        "    print(' '.join(construct_better_line(7)))\n",
        "    print(' '.join(construct_better_line(5)))\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77UZEgS2wgm-"
      },
      "source": [
        "There are various ways this could be improved.  This homework has taken almost long enough.  Just one more thing to try, and this might be mildly difficult.  These poems were based on the \"romance\" genre portion of the Brown corpus.  But the Brown corpus has several other genres.  The command below will list them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEFPPRExwgm-"
      },
      "source": [
        "print(brown.categories())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zdAwjBIwgm-"
      },
      "source": [
        "Go back up to where we first defined `corp` as being `brown.words(categories='romance')`.  And then we defined `lc_corp` as the lowercased words.  And then we defined `pairs_in_cmu` to filter those down to just the words we have pronunciations for.  And defined `cfd` as a conditional frequency distribution of those words.  Then defined `num_next` as being a list of how many continuations each word has, and sorted it into `sorted_next` and then built `good_starts` from that.\n",
        "\n",
        "If you were to retrace those steps after defining `corp` to draw words from the \"science_fiction\" genre instead, how might our haikus change?\n",
        "\n",
        "In the end, you need to wind up with `good_starts`, `next_words`, and `cfd` defined for the corpus before `construct_better_line()` will use the new corpus."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVKUz9i3wgm-"
      },
      "source": [
        "---\n",
        "\n",
        "## TASK 13 Make science fiction haikus\n",
        "\n",
        "Produce a couple of haikus based on the word sequencing in the \"science_fiction\" genre within the Brown corpus, and comment on how they seem to differ or not from the ones we build with the \"romance\" genre."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCdsVKCYwgm_"
      },
      "source": [
        "# Answer 13: retrace the steps from corpus to haiku to make \"science_fiction\" haikus"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lVxnVFiwgm_"
      },
      "source": [
        "**Answer 13**. (markdown)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## TASK 14 Rhyming (extra, advanced)\n",
        "\n",
        "Given that this is a pronunciation dictionary, we could also use it to make rhyming poetry.  And given that the stress is retrievable, we could also use it to assess meter.  You could use it to write a limerick, in fact, if we assume a limerick looks like:\n",
        "\n",
        "```\n",
        "- x - - x - - x - (a)\n",
        "- x - - x - - x - (a)\n",
        "- - x - - x (b)\n",
        "- - x - - x (b)\n",
        "- x - - x - - x - (a)\n",
        "```\n",
        "\n",
        "To be frank, at the point of handing this out, I haven't tried.  But we can see what kind of thing it would require.  First, determining the meter of the words so we can limit the continuation options in a line not just by syllable counts but by matching meter.  And then a way to see when two lines rhyme.  We could say a rhyme occurs when last vowel and following phones match.  In limericks, the (a) rhyme is actually usually deeper, the match is between the penulimate vowel and the material following it.  Which can cross word boundaries (*Nantucket*, *bucket*, *struck it*).  Rhyming is hard enough that it might better to start at the end of the line (with the rhyme) and work backwards.\n",
        "\n",
        "This is an open-ended and optional project, but if you found the haikus too easy, it might be more fun to see if you can generate limericks."
      ],
      "metadata": {
        "id": "zPGilwVywgm_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(pro['nantucket'])\n",
        "print(pro['bucket'])\n",
        "print(pro['stuck'])\n",
        "print(pro['it'])"
      ],
      "metadata": {
        "id": "pDmPCAdOt9I-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(pro['car'])\n",
        "print(pro['bar'])\n",
        "print(pro['star'])"
      ],
      "metadata": {
        "id": "SFdh55qqzSvF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}